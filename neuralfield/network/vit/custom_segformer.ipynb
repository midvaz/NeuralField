{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4afec81",
   "metadata": {},
   "source": [
    "# Custom SegFormer Notebook\n",
    "\n",
    "_Jupyter notebook implementing a custom SegFormer-like model for 5-channel segmentation_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfbc78d",
   "metadata": {},
   "source": [
    "## 1. Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c8a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fffe720",
   "metadata": {},
   "source": [
    "## 2. Определение PatchEmbed и TransformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc1eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, in_channels: int, embed_dim: int, patch_size: int, stride: int, padding: int=None):\n",
    "        super().__init__()\n",
    "        if padding is None:\n",
    "            padding = patch_size // 2\n",
    "        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=stride, padding=padding)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.proj(x)\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = self.norm(x)\n",
    "        x = x.transpose(1, 2).reshape(B, C, H, W)\n",
    "        return x\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, dim: int, num_heads: int, mlp_ratio: float = 4.0, drop_path: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = nn.MultiheadAttention(dim, num_heads, batch_first=True)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, dim)\n",
    "        )\n",
    "        self.drop_path = nn.Identity()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, C, H, W = x.shape\n",
    "        x_flat = x.flatten(2).transpose(1, 2)\n",
    "        x_norm = self.norm1(x_flat)\n",
    "        attn_out, _ = self.attn(x_norm, x_norm, x_norm)\n",
    "        x_flat = x_flat + self.drop_path(attn_out)\n",
    "        x_norm2 = self.norm2(x_flat)\n",
    "        mlp_out = self.mlp(x_norm2)\n",
    "        x_flat = x_flat + self.drop_path(mlp_out)\n",
    "        x = x_flat.transpose(1, 2).reshape(B, C, H, W)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fa3db2",
   "metadata": {},
   "source": [
    "## 3. Определение CustomSegFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e4096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSegFormer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int = 5,\n",
    "        num_classes: int = 9,\n",
    "        embed_dims: List[int] = [64, 128, 320, 512],\n",
    "        num_heads: List[int] = [1, 2, 5, 8],\n",
    "        depths: List[int] = [3, 4, 6, 3],\n",
    "        mlp_ratio: float = 4.0,\n",
    "        decoder_dim: int = 256,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert len(embed_dims) == 4 and len(num_heads) == 4 and len(depths) == 4\n",
    "        self.stages = nn.ModuleList()\n",
    "        in_ch = in_channels\n",
    "        patch_sizes = [7, 3, 3, 3]\n",
    "        strides = [4, 2, 2, 2]\n",
    "        for i in range(4):\n",
    "            layers = []\n",
    "            layers.append(PatchEmbed(in_ch, embed_dims[i], patch_sizes[i], strides[i]))\n",
    "            for _ in range(depths[i]):\n",
    "                layers.append(TransformerBlock(embed_dims[i], num_heads[i], mlp_ratio))\n",
    "            self.stages.append(nn.Sequential(*layers))\n",
    "            in_ch = embed_dims[i]\n",
    "        self.proj_convs = nn.ModuleList([\n",
    "            nn.Conv2d(embed_dims[i], decoder_dim, kernel_size=1) for i in range(4)\n",
    "        ])\n",
    "        self.head = nn.Conv2d(decoder_dim * 4, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        feats = []\n",
    "        for stage in self.stages:\n",
    "            x = stage(x)\n",
    "            feats.append(x)\n",
    "        H0, W0 = feats[0].shape[2:]\n",
    "        proj_feats = []\n",
    "        for idx, feat in enumerate(feats):\n",
    "            p = self.proj_convs[idx](feat)\n",
    "            if p.shape[2:] != (H0, W0):\n",
    "                p = F.interpolate(p, size=(H0, W0), mode='bilinear', align_corners=False)\n",
    "            proj_feats.append(p)\n",
    "        x_dec = torch.cat(proj_feats, dim=1)\n",
    "        x_dec = self.head(x_dec)\n",
    "        scale_factor = 4 * 2 * 2 * 2\n",
    "        x_dec = F.interpolate(x_dec, scale_factor=scale_factor, mode='bilinear', align_corners=False)\n",
    "        return x_dec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149455e0",
   "metadata": {},
   "source": [
    "## 4. Тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58a8ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomSegFormer(in_channels=5, num_classes=9)\n",
    "x = torch.randn(1, 5, 512, 512)\n",
    "y = model(x)\n",
    "print(\"Output shape:\", y.shape)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
